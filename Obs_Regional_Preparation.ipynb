{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#%matplotlib inline \n",
    "\n",
    "###########\n",
    "#PDF PROCESSING FOR various INPUT \n",
    "# DEPENDING ON THE PDF_PROCESSING CLASS\n",
    "#by Carl Schleussner, Climate Analytics\n",
    "#carl.schleussner@climateanalytics.org\n",
    "###########\n",
    "\n",
    "# IMPORT AND CONFIG \n",
    "import numpy as np\n",
    "import netCDF4 as net\n",
    "import dimarray as da \n",
    "import sys,glob,datetime,pickle,os,itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt \n",
    "from netCDF4 import Dataset,netcdftime,num2date\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "\n",
    "#plt.style.use('ggplot')\n",
    "#plt.rcParams['figure.figsize'] = 8,6\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "\n",
    "os.chdir('/Users/peterpfleiderer/Documents/Projects/0p5_observed/pdf_processing/')\n",
    "try:\n",
    "    import pdf_processing as pdf; reload(pdf)\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"cannot find PDF_Processing code\")\n",
    "\n",
    "###########\n",
    "# Settings\n",
    "###########\n",
    "\n",
    "# PDF Method (currently defined: hist, python_silverman)\n",
    "pdf_method='python_silverman'\n",
    "\n",
    "# variables\n",
    "varin_dict={\n",
    "    'TXx':{'var_name':'TXX','longname':'Hot extremes (TXx)','unit':'TXx [$^\\circ$ C]'}}\n",
    "\n",
    "# time informations and periods\n",
    "timeaxis=np.arange(1958,2011)\n",
    "ref_period=[1960,1979]\n",
    "target_periods=[[1991,2010],ref_period]\n",
    "period_names=['Recent','ref']\n",
    "\n",
    "# Set range for years for bootstrap sampling \n",
    "bs_range=[1958,2010]\n",
    "\n",
    "# Input datasets\n",
    "datasets=['HadEX2','GHCNDEX']\n",
    "\n",
    "varoutdict={\n",
    "    datasets[0]:{},    \n",
    "    datasets[1]:{},    \n",
    "}\n",
    "\n",
    "# Set plottint colours\n",
    "colordict={\n",
    "    datasets[0]:\"#247a9c\",\n",
    "    datasets[1]:\"#df1a20\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# HadEx2 & GHCND\n",
    "##############\n",
    "\n",
    "for varin in varin_dict.keys():\n",
    "    for dataset in ['HadEX2','GHCNDEX']:\n",
    "        print varin,dataset\n",
    "        if dataset =='HadEX2':\n",
    "            read_in_data=da.read_nc('/Users/peterpfleiderer/Box Sync/0p5_observational_record/data/data_climdex/HadEx2/H2_'+varin_dict[varin]['var_name']+'_1901-2010_RegularGrid_global_3.75x2.5deg_LSmask.nc')['Ann']\n",
    "        elif dataset =='GHCNDEX':\n",
    "            read_in_data=da.read_nc('/Users/peterpfleiderer/Box Sync/0p5_observational_record/data/data_climdex/GHCND/GHCND_'+varin_dict[varin]['var_name']+'_1951-2016_RegularGrid_global_2.5x2.5deg_LSmask.nc')['Ann']\n",
    "        \n",
    "        # Set regular integer time axis, dimarray default always adds month and day. Time range 1958-2010\n",
    "        input_data=da.DimArray(read_in_data[19580101:20100101,:,:], axes=[timeaxis, read_in_data.lat, read_in_data.lon],dims=['year', 'lat', 'lon'] )\n",
    "        \n",
    "        # mask Greenland\n",
    "        landmask=input_data.ix[10,:,:].copy()\n",
    "        landmask[:,:]=1\n",
    "        if dataset =='HadEX2': \n",
    "            GRL_mask=Dataset('support/GRL_73x96_lat_weighted.nc4').variables['GRL'][:,:]\n",
    "        if dataset == 'GHCNDEX':\n",
    "            GRL_mask=Dataset('support/GRL_73x144_lat_weighted.nc4').variables['GRL'][:,:]\n",
    "        landmask[np.isfinite(GRL_mask)]=0 \n",
    "            \n",
    "        # Mask for data availability (individual for each dataset)\n",
    "        varoutdict[dataset][varin]=pdf.PDF_Processing(varin)\n",
    "        varoutdict[dataset][varin].mask_for_ref_period_data_coverage(input_data,ref_period,check_ref_period_only=False,target_periods=target_periods,landmask=landmask,required_coverage=0.8,dataset=dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# Prepare Polygons\n",
    "##############\n",
    "\n",
    "os.chdir('/Users/peterpfleiderer/Documents/')\n",
    "\n",
    "\n",
    "m = Basemap()\n",
    "m.readshapefile(\"masks/shapefiles/world/ne_50m_admin_0_countries\", 'admin', drawbounds=False)\n",
    "\n",
    "region_polygons={}\n",
    "\n",
    "# Europe\n",
    "name='Europe'\n",
    "region_polygons.pop(name, None)\n",
    "for shape, region in zip(m.admin, m.admin_info):\n",
    "    region = {k.lower():v for k,v in region.items()}    \n",
    "    if region['continent'] in ['Europe'] and region['admin']!='Russia':\n",
    "        #print region['admin']\n",
    "        if name in region_polygons.keys():\n",
    "            region_polygons[name] = \\\n",
    "            region_polygons[name].symmetric_difference(Polygon(shape))\n",
    "        else:\n",
    "            region_polygons[name] = Polygon(shape)\n",
    "\n",
    "region_polygons['Europe']=region_polygons['Europe'].intersection(Polygon([[0,35],[50,35],[50,70],[0,70]])).symmetric_difference(region_polygons['Europe'].intersection(Polygon([[-30,35],[0,35],[0,70],[-30,70]])))\n",
    "\n",
    "# North_America\n",
    "name='North_America'\n",
    "region_polygons.pop(name, None)\n",
    "for shape, region in zip(m.admin, m.admin_info):\n",
    "    region = {k.lower():v for k,v in region.items()}    \n",
    "    if region['admin'] in ['United States of America', 'Canada']:\n",
    "        if name in region_polygons.keys():\n",
    "            region_polygons[name] = \\\n",
    "            region_polygons[name].symmetric_difference(Polygon(shape))\n",
    "        else:\n",
    "            region_polygons[name] = Polygon(shape)\n",
    "\n",
    "# Russia\n",
    "name='Russia'\n",
    "region_polygons.pop(name, None)\n",
    "for shape, region in zip(m.admin, m.admin_info):\n",
    "    region = {k.lower():v for k,v in region.items()}    \n",
    "    if region['admin'] in ['Russia']:\n",
    "        if name in region_polygons.keys():\n",
    "            region_polygons[name] = \\\n",
    "            region_polygons[name].symmetric_difference(Polygon(shape))\n",
    "        else:\n",
    "            region_polygons[name] = Polygon(shape)\n",
    "\n",
    "# Australia\n",
    "name='Australia'\n",
    "region_polygons.pop(name, None)\n",
    "for shape, region in zip(m.admin, m.admin_info):\n",
    "    region = {k.lower():v for k,v in region.items()}    \n",
    "    if region['admin'] in ['Australia']:\n",
    "        if name in region_polygons.keys():\n",
    "            region_polygons[name] = \\\n",
    "            region_polygons[name].symmetric_difference(Polygon(shape))\n",
    "        else:\n",
    "            region_polygons[name] = Polygon(shape)\n",
    "\n",
    "# Asia\n",
    "name='Asia'\n",
    "region_polygons.pop(name, None)\n",
    "for shape, region in zip(m.admin, m.admin_info):\n",
    "    region = {k.lower():v for k,v in region.items()}    \n",
    "    if region['subregion'] in ['Eastern Asia', 'Southern Asia', 'Central Asia'] and region['admin']!='Russia':\n",
    "        #print region['admin']\n",
    "        #print region\n",
    "        if name in region_polygons.keys():\n",
    "            try:\n",
    "                region_polygons[name] = \\\n",
    "                region_polygons[name].symmetric_difference(Polygon(shape))\n",
    "            except:\n",
    "                print 'problem with',region['admin']\n",
    "        else:\n",
    "            region_polygons[name] = Polygon(shape)\n",
    "            \n",
    "#continent_polygons={}\n",
    "#continent_polygons['Oceania']=Polygon([[110,-10],[180,-10],[180,-50],[110,-50]])\n",
    "#continent_polygons['North_America']=Polygon([[-170,25],[-50,25],[-50,70],[-170,70]])\n",
    "#continent_polygons['Europe']=Polygon([[0,35],[50,35],[50,70],[0,70]]).symmetric_difference(Polygon([[-30,35],[0,35],[0,70],[-30,70]]))\n",
    "\n",
    "with open('EU_NA_AS_RU_AU_polygons.pkl', 'wb') as output:\n",
    "    pickle.dump(region_polygons, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# Regional Masking\n",
    "##############\n",
    "\n",
    "for varin in varin_dict.keys():\n",
    "    for dataset in ['HadEX2','GHCNDEX']:\n",
    "        varoutdict[dataset][varin].derive_regional_masking(shift_lon=-180.0,region_polygons=region_polygons,region_type='EU_NA_AS_RU_AU',dataset=dataset,overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# get PDFs and bootstrap\n",
    "###############\n",
    "\n",
    "cut_interval_dict={\n",
    "    'TXx':[-2,3]}\n",
    "\n",
    "for varin in varin_dict.keys():\n",
    "    print '\\n-------------------',varin    \n",
    "    for dataset in ['HadEX2','GHCNDEX']:\n",
    "        print dataset\n",
    "        # relative diff for precipitation indices\n",
    "        if varin in ['RX5','RX1']:relative_diff=True\n",
    "        if varin not in ['RX5','RX1']:relative_diff=False\n",
    "            \n",
    "        varoutdict[dataset][varin].derive_time_slices(ref_period,target_periods,period_names)\n",
    "        varoutdict[dataset][varin].derive_distributions()\n",
    "            \n",
    "        varoutdict[dataset][varin].derive_pdf_difference('ref','Recent',pdf_method=pdf_method,bin_range=cut_interval_dict[varin],relative_diff=relative_diff)\n",
    "\n",
    "        # Get bootstrapping confidence intervals\n",
    "        varoutdict[dataset][varin].bootstrapping(bs_range,100)   \n",
    "        varoutdict[dataset][varin].derive_bootstrapped_conf_interval(pdf_method=pdf_method,relative_diff=relative_diff)\n",
    "        print '...........................'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../varoutdict_10000_obs_0p8_regional.pkl', 'wb') as output:\n",
    "    pickle.dump(varoutdict, output, pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py_masks]",
   "language": "python",
   "name": "conda-env-py_masks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
